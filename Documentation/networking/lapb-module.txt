ory Controller Option 1 register value
 *          currently set for the controller, from which the memory type
 *          is derived.
 *
 * This routine returns the EDAC memory type appropriate for the
 * current controller configuration.
 *
 * Returns a memory type enumeration.
 */
static enum mem_type ppc4xx_edac_get_mtype(u32 mcopt1)
{
	bool rden = ((mcopt1 & SDRAM_MCOPT1_RDEN_MASK) == SDRAM_MCOPT1_RDEN);

	switch (mcopt1 & SDRAM_MCOPT1_DDR_TYPE_MASK) {
	case SDRAM_MCOPT1_DDR2_TYPE:
		return rden ? MEM_RDDR2 : MEM_DDR2;
	case SDRAM_MCOPT1_DDR1_TYPE:
		return rden ? MEM_RDDR : MEM_DDR;
	default:
		return MEM_UNKNOWN;
	}
}

/**
 * ppc4xx_edac_init_csrows - initialize driver instance rows
 * @mci: A pointer to the EDAC memory controller instance
 *       associated with the ibm,sdram-4xx-ddr2 controller for which
 *       the csrows (i.e. banks/ranks) are being initialized.
 * @mcopt1: The 32-bit Memory Controller Option 1 register value
 *          currently set for the controller, from which bank width
 *          and memory typ information is derived.
 *
 * This routine initializes the virtual "chip select rows" associated
 * with the EDAC memory controller instance. An ibm,sdram-4xx-ddr2
 * controller bank/rank is mapped to a row.
 *
 * Returns 0 if OK; otherwise, -EINVAL if the memory bank size
 * configuration cannot be determined.
 */
static int ppc4xx_edac_init_csrows(struct mem_ctl_info *mci, u32 mcopt1)
{
	const struct ppc4xx_edac_pdata *pdata = mci->pvt_info;
	int status = 0;
	enum mem_type mtype;
	enum dev_type dtype;
	enum edac_type edac_mode;
	int row, j;
	u32 mbxcf, size, nr_pages;

	/* Establish the memory type and width */

	mtype = ppc4xx_edac_get_mtype(mcopt1);
	dtype = ppc4xx_edac_get_dtype(mcopt1);

	/* Establish EDAC mode */

	if (mci->edac_cap & EDAC_FLAG_SECDED)
		edac_mode = EDAC_SECDED;
	else if (mci->edac_cap & EDAC_FLAG_EC)
		edac_mode = EDAC_EC;
	else
		edac_mode = EDAC_NONE;

	/*
	 * Initialize each chip select row structure which correspond
	 * 1:1 with a controller bank/rank.
	 */

	for (row = 0; row < mci->nr_csrows; row++) {
		struct csrow_info *csi = mci->csrows[row];

		/*
		 * Get the configuration settings for this
		 * row/bank/rank and skip disabled banks.
		 */

		mbxcf = mfsdram(&pdata->dcr_host, SDRAM_MBXCF(row));

		if ((mbxcf & SDRAM_MBCF_BE_MASK) != SDRAM_MBCF_BE_ENABLE)
			continue;

		/* Map the bank configuration size setting to pages. */

		size = mbxcf & SDRAM_MBCF_SZ_MASK;

		switch (size) {
		case SDRAM_MBCF_SZ_4MB:
		case SDRAM_MBCF_SZ_8MB:
		case SDRAM_MBCF_SZ_16MB:
		case SDRAM_MBCF_SZ_32MB:
		case SDRAM_MBCF_SZ_64MB:
		case SDRAM_MBCF_SZ_128MB:
		case SDRAM_MBCF_SZ_256MB:
		case SDRAM_MBCF_SZ_512MB:
		case SDRAM_MBCF_SZ_1GB:
		case SDRAM_MBCF_SZ_2GB:
		case SDRAM_MBCF_SZ_4GB:
		case SDRAM_MBCF_SZ_8GB:
			nr_pages = SDRAM_MBCF_SZ_TO_PAGES(size);
			break;
		default:
			ppc4xx_edac_mc_printk(KERN_ERR, mci,
					      "Unrecognized memory bank %d "
					      "size 0x%08x\n",
					      row, SDRAM_MBCF_SZ_DECODE(size));
			status = -EINVAL;
			goto done;
		}

		/*
		 * It's unclear exactly what grain should be set to
		 * here. The SDRAM_ECCES register allows resolution of
		 * an error down to a nibble which would potentially
		 * argue for a grain of '1' byte, even though we only
		 * know the associated address for uncorrectable
		 * errors. This value is not used at present for
		 * anything other than error reporting so getting it
		 * wrong should be of little consequence. Other
		 * possible values would be the PLB width (16), the
		 * page size (PAGE_SIZE) or the memory width (2 or 4).
		 */
		for (j = 0; j < csi->nr_channels; j++) {
			struct dimm_info *dimm = csi->channels[j]->dimm;

			dimm->nr_pages  = nr_pages / csi->nr_channels;
			dimm->grain	= 1;

			dimm->mtype	= mtype;
			dimm->dtype	= dtype;

			dimm->edac_mode	= edac_mode;
		}
	}

 done:
	return status;
}

/**
 * ppc4xx_edac_mc_init - initialize driver instance
 * @mci: A pointer to the EDAC memory controller instance being
 *       initialized.
 * @op: A pointer to the OpenFirmware device tree node associated
 *      with the controller this EDAC instance is bound to.
 * @dcr_host: A pointer to the DCR data containing the DCR mapping
 *            for this controller instance.
 * @mcopt1: The 32-bit Memory Controller Option 1 register value
 *          currently set for the controller, from which ECC capabilities
 *          and scrub mode are derived.
 *
 * This routine performs initialization of the EDAC memory controller
 * instance and related driver-private data associated with the
 * ibm,sdram-4xx-ddr2 memory controller the instance is bound to.
 *
 * Returns 0 if OK; otherwise, < 0 on error.
 */
static int ppc4xx_edac_mc_init(struct mem_ctl_info *mci,
			       struct platform_device *op,
			       const dcr_host_t *dcr_host, u32 mcopt1)
{
	int status = 0;
	const u32 memcheck = (mcopt1 & SDRAM_MCOPT1_MCHK_MASK);
	struct ppc4xx_edac_pdata *pdata = NULL;
	const struct device_node *np = op->dev.of_node;

	if (of_match_device(ppc4xx_edac_match, &op->dev) == NULL)
		return -EINVAL;

	/* Initial driver pointers and private data */

	mci->pdev		= &op->dev;

	dev_set_drvdata(mci->pdev, mci);

	pdata			= mci->pvt_info;

	pdata->dcr_host		= *dcr_host;
	pdata->irqs.sec		= NO_IRQ;
	pdata->irqs.ded		= NO_IRQ;

	/* Initialize controller capabilities and configuration */

	mci->mtype_cap		= (MEM_FLAG_DDR | MEM_FLAG_RDDR |
				   MEM_FLAG_DDR2 | MEM_FLAG_RDDR2);

	mci->edac_ctl_cap	= (EDAC_FLAG_NONE |
				   EDAC_FLAG_EC |
				   EDAC_FLAG_SECDED);

	mci->scrub_cap		= SCRUB_NONE;
	mci->scrub_mode		= SCRUB_NONE;

	/*
	 * Update the actual capabilites based on the MCOPT1[MCHK]
	 * settings. Scrubbing is only useful if reporting is enabled.
	 */

	switch (memcheck) {
	case SDRAM_MCOPT1_MCHK_CHK:
		mci->edac_cap	= EDAC_FLAG_EC;
		break;
	case SDRAM_MCOPT1_MCHK_CHK_REP:
		mci->edac_cap	= (EDAC_FLAG_EC | EDAC_FLAG_SECDED);
		mci->scrub_mode	= SCRUB_SW_SRC;
		break;
	default:
		mci->edac_cap	= EDAC_FLAG_NONE;
		break;
	}

	/* Initialize strings */

	mci->mod_name		= PPC4XX_EDAC_MODULE_NAME;
	mci->mod_ver		= PPC4XX_EDAC_MODULE_REVISION;
	mci->ctl_name		= ppc4xx_edac_match->compatible,
	mci->dev_name		= np->full_name;

	/* Initialize callbacks */

	mci->edac_check		= ppc4xx_edac_check;
	mci->ctl_page_to_phys	= NULL;

	/* Initialize chip select rows */

	status = ppc4xx_edac_init_csrows(mci, mcopt1);

	if (status)
		ppc4xx_edac_mc_printk(KERN_ERR, mci,
				      "Failed to initialize rows!\n");

	return status;
}

/**
 * ppc4xx_edac_register_irq - setup and register controller interrupts
 * @op: A pointer to the OpenFirmware device tree node associated
 *      with the controller this EDAC instance is bound to.
 * @mci: A pointer to the EDAC memory controller instance
 *       associated with the ibm,sdram-4xx-ddr2 controller for which
 *       interrupts are being registered.
 *
 * This routine parses the correctable (CE) and uncorrectable error (UE)
 * interrupts from the device tree node and maps and assigns them to
 * the associated EDAC memory controller instance.
 *
 * Returns 0 if OK; otherwise, -ENODEV if the interrupts could not be
 * mapped and assigned.
 */
static int ppc4xx_edac_register_irq(struct platform_device *op,
				    struct mem_ctl_info *mci)
{
	int status = 0;
	int ded_irq, sec_irq;
	struct ppc4xx_edac_pdata *pdata = mci->pvt_info;
	struct device_node *np = op->dev.of_node;

	ded_irq = irq_of_parse_and_map(np, INTMAP_ECCDED_INDEX);
	sec_irq = irq_of_parse_and_map(np, INTMAP_ECCSEC_INDEX);

	if (ded_irq == NO_IRQ || sec_irq == NO_IRQ) {
		ppc4xx_edac_mc_printk(KERN_ERR, mci,
				      "Unable to map interrupts.\n");
		status = -ENODEV;
		goto fail;
	}

	status = request_irq(ded_irq,
			     ppc4xx_edac_isr,
			     0,
			     "[EDAC] MC ECCDED",
			     mci);

	if (status < 0) {
		ppc4xx_edac_mc_printk(KERN_ERR, mci,
				      "Unable to request irq %d for ECC DED",
				      ded_irq);
		status = -ENODEV;
		goto fail1;
	}

	status = request_irq(sec_irq,
			     ppc4xx_edac_isr,
			     0,
			     "[EDAC] MC ECCSEC",
			     mci);

	if (status < 0) {
		ppc4xx_edac_mc_printk(KERN_ERR, mci,
				      "Unable to request irq %d for ECC SEC",
				      sec_irq);
		status = -ENODEV;
		goto fail2;
	}

	ppc4xx_edac_mc_printk(KERN_INFO, mci, "ECCDED irq is %d\n", ded_irq);
	ppc4xx_edac_mc_printk(KERN_INFO, mci, "ECCSEC irq is %d\n", sec_irq);

	pdata->irqs.ded = ded_irq;
	pdata->irqs.sec = sec_irq;

	return 0;

 fail2:
	free_irq(sec_irq, mci);

 fail1:
	free_irq(ded_irq, mci);

 fail:
	return status;
}

/**
 * ppc4xx_edac_map_dcrs - locate and map controller registers
 * @np: A pointer to the device tree node containing the DCR
 *      resources to map.
 * @dcr_host: A pointer to the DCR data to populate with the
 *            DCR mapping.
 *
 * This routine attempts to locate in the device tree and map the DCR
 * register resources associated with the controller's indirect DCR
 * address and data windows.
 *
 * Returns 0 if the DCRs were successfully mapped; otherwise, < 0 on
 * error.
 */
static int ppc4xx_edac_map_dcrs(const struct device_node *np,
				dcr_host_t *dcr_host)
{
	unsigned int dcr_base, dcr_len;

	if (np == NULL || dcr_host == NULL)
		return -EINVAL;

	/* Get the DCR resource extent and sanity check the values. */

	dcr_base = dcr_resource_start(np, 0);
	dcr_len = dcr_resource_len(np, 0);

	if (dcr_base == 0 || dcr_len == 0) {
		ppc4xx_edac_printk(KERN_ERR,
				   "Failed to obtain DCR property.\n");
		return -ENODEV;
	}

	if (dcr_len != SDRAM_DCR_RESOURCE_LEN) {
		ppc4xx_edac_printk(KERN_ERR,
				   "Unexpected DCR length %d, expected %d.\n",
				   dcr_len, SDRAM_DCR_RESOURCE_LEN);
		return -ENODEV;
	}

	/*  Attempt to map the DCR extent. */

	*dcr_host = dcr_map(np, dcr_base, dcr_len);

	if (!DCR_MAP_OK(*dcr_host)) {
		ppc4xx_edac_printk(KERN_INFO, "Failed to map DCRs.\n");
		    re